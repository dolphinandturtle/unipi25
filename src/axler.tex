\include{packages}
\include{definitions}
\usepackage[english]{babel}

\begin{document}
\section*{``Linear Algebra Done Right (4th edition)'' by Sheldon Axler}
\begin{multicols}{3}
  1) Linear algebra, the study of linear maps on finite-dimensional vector
  spaces. Complex numbers are needed for some theorems.
  2) Complex numbers purpose, intuition and definition motivated by it.
  3) Properties of complex arithmetic, commutativity proof.
  4) Complex subtraction and division. Field as an alias and scalar power.
  5) Low dimension sets geometry. List definition, notation and difference from
  sets.
  6) Coordinate space definition, geometric intuition limit and coordinate
  addition definition.
  7) Commutativity of coordinate addition, coordinate notation expansion and
  shorthand for additive identity.
  8) Geometric properties of vectors and adding geometrically in $\reals^2$.
  9) Coordinate additive inverse definition and its geometric interpretation in
  $\reals^2$, coordinates scalar multiplication motivation, definition and
  scaling geometrically in $\reals^2$.
  10) Digression on fields, small field and relevance of fields in theorems.
  12) Vector spaces, extracting operation properties from coordinate spaces.
  Addition, scalar multiplication, vector space and vector definitions.
  13) Field choice over scalar multiplication. Fixed field vector spaces.
  coordinate space and sequence space as vector spaces. Set of functions notation
  and operation definition.
  14) Set of functions as vector spaces. Unique additive identity for vector
  spaces.
  15) Unique additive inverse for vector spaces, vector inverse notations,
  vector space absorbent scalar.
  16) Vector space absorbent vector, vector space scalar inversion.
  18) Subspace definition and conditions for it.
  19) Subspace examples, linearity of calculus, subspaces of $\reals^2$ and
  $\reals^3$ . Definition of sum of subspaces.
  20) Sum of subspaces examples.
  21) Sum of subspaces is the smallest containing subspace. Definition of direct
  sum and example.
  22) Example and counter examples for direct sums.
  23) Condition for a direct sum. Direct sum of two subspaces.
  24) Direct sum of multiple subspaces.
  27) Finite-dimensional vector spaces.
  28) List of vectors notation. Definition of linear combination and example.
  29) Definition of span and example. Span is the smallest containing subspace.
  Definition of spanning.
  30) Spanning coordinate space. Definition of finite-dimensional vector space.
  Definition of polynomial space and vector structure and unique coefficients.
  31) Definition of degree of polynomial. Definition of m-polynomial space.
  Definition of infinite-dimensional vector space, like polynomial space.
  Motivating linear indipendence
  32) Definition of linear independence and examples.
  33) Definition of linear dependence and examples. Linear dependence lemma.
  34) Linear dependence lemma edge case and example.
  35) Lenght of linearly independent list greater then lenght of spanning list.
  36) Lenght of vector lists examples. Finite-dimensional subspaces.
  39) Definition of basis and examples. Criterion for basis.
  40) Every spanning list contains a basis.
  41) Basis of finite-dimensional vector space. Every linearly independent list
  extends to a basis.
  42) Every subspace is part of a direct sum equal to the entire space.
  44) Intuition for dimension following coordinate space standard basis.
  Basis lenght does not depend on basis. Definition of dimension and examples.
  45) Dimension of a subspace. Linearly independent list of the right lenght is a
  basis. Subspace of full dimension equals the whole space.
  46) Basis for linearly independent list examples. Spanning list of the right
  lenght is a basis.
  47) Dimension of a sum.
  48) Comparing finite sets with finite-dimensional vector spaces.
  51) Correspondence between linear maps and matrices.
  52) Definition, notation and examples for linear map.
  53) More examples for linear maps.
  54) Linear map lemma.
  55) Definition of addition and scalar multiplication between linear maps.
  The linear map space is a vector space. Definition of product of linear maps.
  56) Algebraic properties of products of linear maps with examples. An linear
  maps takes zero to zero.
  59) Definition and examples of null space. The null space is a subspace.
  60) Definition of injective. Injectivity is equivalent to null space with
  only zero.
  61) Definition and examples of range. The range is a subspace.
  62) Definition and example of surjective. The fundamental theorem of linear
  maps.
  63) Linear map to a lower-dimensional space is not injective and example.
  64) Linear map to a higher-dimensional space is not surjective. Expressing
  systems of linear equations in term of linear maps.
  65) Homogeneous system of linear equations. System of linear equations with
  more equations than variables.
  69) Definition and example of matrix. Definition of matrix of a linear map.
  70) Matrix construction, standard basis and examples.
  71) Definition of matrix addition. Matrix of the sum of linear maps.
  Definition of scalar multiplication of a matrix.
  72) Example of addition and scalar multiplication on matrix. The matrix of a
  scalar times a linear map. Notation for m-by-n matrix space. Dimension of a
  matrix. Motivation for matrix multiplication.
  73) Definition and example of matrix multiplication.
  74) Matrix of product of linear maps. Notation for matrix rows and columns
  and example of usage.
  75) Entry of matrix product equals row times column. Column of matrix product
  equals matrix times column. Motivation for matrix product as linear
  combination.
  76) Linear combination of columns. Hint for linear combination of rows and
  developing tools to proove the column-row factorization. Matrix
  multiplication as linear combinations of columns or rows.
  77) Definition and examples of column rank and row rank. Definition of
  transpose of a matrix.
  78) Example of transpose of a matrix. Column-row factorization. Column rank
  equals row rank.
  79) Definition of rank.
  82) Definition of invertible and inverse linear map. Inverse is unique.
  Notation and example for inverse matrix.
  83) Invertibility equals injectivity and surjectivity.
  84) Counter-examples for invertibility. Injectivity is equivalent to
  surjectivity for linear maps between same finite-dimensional vector spaces.
  85) Example for injectivity-surjectivity equivalence. Inverse matrix
  commutativity over base matrix.
  86) Definition of isomorphism and isomorphic. Isomorphism seen as set
  relabeling. Dimensions shows whether vector spaces are isomorphic.
  87) Isomorphism between vector spaces and coordinate spaces based of their
  dimension. Linear transformations are isomorphic to matrices. Dimension of
  linear transformations.
  88) Definition and example of matrix of a vector. Relabeling elements of a
  vector space once a basis is chosen.
  89) The column of a matrix is a transformed basis. Linear maps act like
  matrix multiplication. Matrices induce linear maps from a vector matrix space
  to another. Chosen a basis every linear map can be seen as a matrix
  multiplication operation.
  90) Dimension of the range of a transformation equals the rank of the matrix
  of that transformation. For linear maps from a vector space to itself we
  usually use the same input and output basis. Definition of identity matrix.
  91) Lax notation for identity operator and matrix. Definition of invertible
  and inverse matrix. Uniqueness of the inverse matrix and inverse of the
  product. Matrix of product of linear maps.
  92) Matrix of identity operator with respect to two bases and example.
  93) Change-of-basis formula. Matrix of inverse equals inverse of matrix.
\end{multicols}

\pagebreak

\mychapter{Propositions}

\begin{multicols}{3}
  \mysection{Vector spaces}

  \mydefinition{Complex numbers}
  Ordered pairs of real numbers with addition and multiplication consistent with
  the algebra of a sum between a number and a scaled \textit{root of the negative unit}.

  \mytheorem{Properties of complex arithmetic}
  Commutativity, associativity, identities, inverses and distributivity.

  \mydefinition{Subtraction/Division}
  Adding/Multiplying by the \textit{inverse} of the operand.

  \mydefinition{List of lenght}
  A \textit{finite} set with an \textit{ordering}.

  \mydefinition{Coordinate space}
  \myparagraph{Definition}
  The set of \textit{scalar lists} of a given lenght.
  \myparagraph{Operations}
  Addition and scalar multiplication are defined \textit{coordinatewise}.
  \myparagraph{Elements}
  The \textit{identity element} is a list of zeros, the \textit{inverse}
  of an element is its coordinatewise \textit{scalar inverse}.

  \mydefinition{Vector operations}
  \myparagraph{Addition}
  A map from a space to \textit{its} endomaps.
  \myparagraph{Scalar multiplication}
  A map from a \textit{field} to the endomaps of a space.

  \mydefinition{Vector space}
  An \textit{abelian group} under addition with a \textit{ring homomorphism} from a \textit{field} into the group's \textit{endomorphism ring} as scalar multiplication.

  \mydefinition{Standard vector spaces}
  A real/complex vector space has scalar multiplication defined on the \textit{real/complex field}.

  \mytheorem{Algebraic properties}
  Identity and inverses are unique. Null scaling and scaling null is null. Inverse identity scaling is inverse.

  \mysection{Subspaces}
  \mydefinition{Subspace}
  A subset of a vector space with its \textit{additive identity}, \textit{operations} and properties.
  \myparagraph{Characterization}
  If and only if it contains the additive identity and is \textit{closed} under the operations.

  \mydefinition{Sum of subspaces}
  The set of all \textit{sums between elements} of distinct subspaces.
  \myparagraph{Structure}
  The smallest \textit{subspace} containing the subspaces \textit{individually}.

  \mydefinition{Direct-sum of subspaces}
  A sum of subspaces whose elements can be written as a \textit{unique sum}.
  \myparagraph{Reciprocal characterization}
  If and only if its \textit{null vector} can be written as a unique sum of null vectors.
  \myparagraph{Set characterization}
  If and only if the \textit{intersection} between the operands is trivial.

  \mysection{Span and linear independence}
  \mydefinition{Linear combination of vectors}
  A \textit{sum over an entrywise products} of scalars and vectors.
  
  \mydefinition{Span}
  The set of all \textit{linear combinations} of a list of vectors.
  \myparagraph{Structure}
  The smallest subspace containing the list of vectors.

  \mydefinition{Polynomial with scalar coefficients}
  A field endo-map that sums over the entrywise products of scalars and increasing \textit{whole powers}.
  \myparagraph{Degree}
  The \textit{greatest power} taken, not scaled by zero.
  
  \mydefinition{Cardinality}
  A vector space \textit{spanned} by some list of vectors is \textit{finite-dimensional}, if not then \textit{infinite-dimensional}.
  
  \mydefinition{Linear dependence}
  A list of vectors whose null linear combination implies all coefficients to be zero is \textit{linearly independent},
  if not then \textit{linearly dependent}.
  \myparagraph{Characterization}
  Some in a linearly dependent list of vectors are in the span of their preceding, \textit{they don't affect the first span}.
  
  \mytheorem{List lenght constraint}
  The lenght of a linearly independent list \textit{cannot be greater} than that of a spanning list.
  
  \mytheorem{Finite-dimensional subspace}
  A subspace of a finite-dimensional vector space is finite-dimensional.
  
  \mysection{Bases}
  \mydefinition{Basis of a vector space}
  A list of vectors that is linearly \textit{independent} and that \textit{spans} their vector space.
  
  \mytheorem{Criterion for basis}
  A list of vectors is a basis if and only if every other vector can be written as a \textit{unique linear combination} of it.
  
  \mytheorem{List resizing to a basis}
  Spanning lists of vectors can be \textit{reduced} to a basis. Linearly independent lists of vectors, in a finite-dimensional
  vector space, can be \textit{extended} to a basis.

  \mytheorem{Finite-dimensional vector space basis}
  Finite-dimensional vector spaces have a basis.
  
  \mytheorem{Subspace direct completion}
  For every subspace, in a finite-dimensional vector space there exists a \textit{complement} such that their direct sum equals the whole space.
  
  \mysection{Dimension (finite)}
  \mytheorem{Basis lenght lemma}
  Any pair of bases of a vector space have the \textit{same lenght}.
  
  \mydefinition{Dimension of a vector space}
  The \textit{lenght} of any basis of the vector space.
  
  \mytheorem{Dimension of a subspace}
  The dimension of a subspace \textit{cannot be greater} than the dimension of the whole space.
  
  \mytheorem{Full dimension subspace}
  A subspace whose dimension is \textit{equal} to that of its whole space, is the whole space itself.
  
  \mytheorem{Basis lenght list}
  A list of vectors whose lenght is equal to the full dimension and is linearly independent or spanning, is also a basis.
  
  \mytheorem{Dimension of a sum}
  The dimension of the sum between a pair of subspaces is the sum of their dimensions minus the dimension of their intersection.

  \mysection{Linear maps}
  \mydefinition{Linear map}
  A \textit{group endomorphism} over addition that \textit{commutes} with scalar multiplication.
  \myparagraph{Characterization}
  Elements of a basis can be linearly mapped to anything, and the map is unique.
  \myparagraph{Operations}
  Map addition and scalar multiplication is \textit{pointwise}.
  \myparagraph{Structure}
  The space of linear maps with map addition and scalar multiplication is a \textit{vector space}.

  \mydefinition{Product of linear maps}
  The product of maps gives their \textit{composition}.
  \myparagraph{Algebraic properties}
  Associativity, identity and distributivity over addition.

  \mytheorem{Mapped null}
  Null vectors are linearly mapped into themselves.

  \mydefinition{Null space}
  The set of elements mapped into \textit{null vectors} by a given linear map.
  \myparagraph{Structure}
  The null space is a \textit{subspace} of the domain of a linear map.

  \mydefinition{Injective}
  A map whose distinct elements are \textit{distinctly mapped}.
  \myparagraph{Characterization}
  A linear map is injective if and only if the null space is trivial.

  \mydefinition{Range}
  The set of elements \textit{mapped} by a given linear map.
  \myparagraph{Structure}
  The range is a subspace of the \textit{codomain} of a linear map.

  \mydefinition{Surjective}
  A map whose range equals its codomain.

  \mytheorem{Fundamental theorem}
  A linear map's domain dimension is equal to the sum between the dimensions of its null space and range.

  \mytheorem{Linear maps dimension}
  In matters of dimension, higher isn't \textit{into} lower and lower isn't \textit{onto} higher.

  \mytheorem{Solution of linear systems}
  \paragraph{\textbf{Homogeneous}}
  A system of linear equations with more variables than equations and null costant terms, has \textit{non-zero solutions}.
  
  \paragraph{\textbf{Eterogeneous}}
  A system of linear equations with more equation than variables has \textit{no solution} for some choice of constant terms.
  
  \mysection{Matrices}
  \mydefinition{Matrix}
  A whole rectangle of numbers with a \textit{row-column} index pair.
  \myparagraph{Operations}
  Elementwise \textit{addition} and \textit{scalar multiplication}.
  \myparagraph{Structure}
  The space of matrices of a given size with matrix addition and scalar multiplication is a \textit{vector space}.
  \myparagraph{Dimension}
  The number of rows times the number of columns.
  
  \mydefinition{Linear map matrix form}
  Each column represents a \textit{mapped domain basis} as a linear combination of \textit{codomain basis} with column coefficients.
  
  \mydefinition{Matrix multiplication}
  A map from matrix pairs onto matrices where entries are sums over the component-wise product of
  the pair's row a column respectively.
  
  \mytheorem{Conservation map operations}
  Linear maps are \textit{homomorphic} to matrices over \textit{addition}, \textit{scaling} and \textit{multiplication}.

  \mydefinition{Row/column matrices}
  A matrix with \textit{one row/column}.

  \mytheorem{Matrix multiplication entry}
  The product between the corresponding left and right entries' row and column \textit{matrices} respectively.

  \mytheorem{Matrix multiplication column}
  The product between the left matrix and the right corresponding column matrix respectively.

  \mytheorem{Linear combination of columns}
  A matrix multiplication by a column matrix is a linear combination of the
  matrix columns with column matrix coefficients.

  \mytheorem{Matrix multiplication as a linear combination}
  Multiplication columns/rows can be written as the linear combinations of
  left/right columns/rows with
  the corresponding right/left column/row coefficients.
  
  \mydefinition{Column/row rank}
  Dimension of the span of the columns/rows of a matrix.

  \mydefinition{Transpose of a matrix}
  A matrix automap that \textit{inverts} rows and columns.

  \mytheorem{Column-row factorization}
  Every matrix with a column rank greater than zero
  can be written as a product between
  a matrix of \textit{rank-width} and a matrix of \textit{rank-height}.

  \mytheorem{Row-column rank}
  The column rank of a matrix \textit{equals} its row rank.

  \mydefinition{Rank}
  The column rank of a matrix.

  \mysection{Isomorphisms}

  \mydefinition{Inverse}
  A linear map whose left and right product gives the identity map.

  \mytheorem{Inverse choice}
  For a given linear map the inverse is unique.

  \mytheorem{Invertibility characterization}
  A linear map is invertible if and only if it is injective and surjective.

  \mytheorem{Injectivity/surjectivity/invertibility equivalence}
  Injectivity, surjectivity and invertibility in a linear map between two spaces of equal \textit{finite-dimension} are all equivalent.

  \mytheorem{Weak invertibility}
  If the product of \textit{finite-dimensional} linear maps is the identity, the product \textit{commutes}.

  \mydefinition{Isomorphism}
  An invertible linear map.

  \mytheorem{Isomorphism condition}
  Vector spaces of equal finite-dimension are isomorphic.

  \mytheorem{Linear maps and matrices}
  For a given basis of the vector spaces acted upon, the \textit{matrix form} is an
  \textit{isomorphism} from the space of linear maps to the space of matrices.

  \mytheorem{Dimension of a linear map}
  A linear maps dimension is the product between the dimension of its domain and codomain respectively.

  \mydefinition{Matrix of a vector}
  Given a basis of a vector space, a vector's \textit{matrix form} is a \textit{column matrix}.
  % specifying how to determine matrix entries as the coefficients of the linear combination in terms
  % of basis vectors.

  \mytheorem{Columns}
  
  \mytheorem{Linear maps as matrix multiplication}
  The matrix of a linear map acted on a vector is the matrix multiplication between
  the \textit{matrix forms} of the map and vector respectively.
  
  \mytheorem{Range dimension on matrix}
  Given a \textit{finite-dimensional} linear map,
  dimension of its \textit{range} is equal to the \textit{column rank} of its matrix form.
  
  \mydefinition{Identity matrix}
  Square matrix with left to right diagonal filled with 1's.

  \mydefinition{Inverse matrix}
  Given an \textit{invertible} matrix its inverse is such that their product gives the \textit{idenity matrix}.

  \mytheorem{Matrix of product of linear maps}
  The matrix of a linear map product is the product of matrices of the linear maps.
  
  \mytheorem{Identity matrix with bases}
  The matrix of an identity map with respect two its basis
  has inverse equal to itself with inverted basis.
  
  %\mytheorem{Change-of-basis formula}
  
  \mytheorem{Matrix of inverse}
  The matrix of the inverse linear map is the inverse matrix of the linear map.

  \mysection{Products and Quotients}

  \mydefinition{Product of vector spaces}
  \myparagraph{Definition}
  The set of lists of vectors from the vector spaces respectively.
  \myparagraph{Addition}
  Entrywise addition.
  \myparagraph{Scalar multiplication}
  Entrywise scalar multiplication.

  \mytheorem{Product of vector spaces structure}
  The product of vector spaces is a \textit{vector space}.

  \mytheorem{Dimension of the product of vector spaces}
  The \textit{sum} of the dimensions of the operand vector spaces.

  \mytheorem{Producs and direct sums}
  Maps from product of spaces two sums of vector spaces is direct if and only if it is \textit{injective}.

  \mytheorem{Direct sum dimension}
  Sums between vector spaces is direct if and only if its dimensions \textit{add up}.

  \mydefinition{Translations of subsets}
  The set of all \textit{vector sums} between a vector and the subset elements.

  \mydefinition{Quotient space}
  The \textit{quotient} between a vector space and a subset of his is the set of all
  \textit{translates} of the subsets.

  \mytheorem{Translates topology}
  Two translates of a subspace are equal or disjoint.

  \mydefinition{Quotient addition}
  The sum of translates of a subset by some vectors
  is the translate of a subset by the sum of vectors.
  
  \mydefinition{Quotient scaling}
  The scaled translate of a subset by a vector
  is the translate of a subset by the scaled vector.

  \mytheorem{Quotient space structure}
  The quotient space is a \textit{vector space}.

  \mydefinition{Quotient map}
  A linear map from a vector space to its quotient that maps vectors
  into the translated subset.

  \mytheorem{Dimension of quotient space}
  The dimension of the quotient between a vector space and a subspace of his
  is a the difference between their dimensions respectively.

  \mydefinition{Tilde map}
  Linear map on the quotient of space with its kernel that
  sends kernel translates into translation vectors.

  \mytheorem{Kernel and range of tilde map}
  Quotient map into tilde map gives the map, tilde map is injective,
  tilde map's range is equal to that of its map and
  the quotient of the domain with the map kernel is isomorphic
  to its map.

  \mysection{Duality}

  \mydefinition{Linear functional}
  A linear map from a vector space to a field.

  \mydefinition{Dual space}
  The vector space of all linear functionals on a vector space.

  \mytheorem{Dimension of the dual space}
  A vector space's dimension and that of its dual are equal.

  \mydefinition{Dual basis}
  Given a basis of a vector space, the basis of its dual
  is a set of functionals that map the starting basis elements
  into 1 and the rest into 0.

  \mytheorem{Coefficient extraction}
  A vector can be expressed as a linear combination of its
  basis with corresponding dual basis elements acting as
  coefficients.

  \mytheorem{Dual basis coherence}
  The dual basis of a vector space is a basis of its dual.

  \mydefinition{Dual map}
  A linear map's dual is a map from the duals of its codomain
  to domain defined by the starting map acted on by an element.

  \mytheorem{Algebraic properties of dual maps}
  Duality \textit{distributes} over addition, scalar multiplication
  and the dual of the product is the \textit{commuted product} of the duals.

  \mydefinition{Annihilator}
  The annihilator of a subspace is the set of all linear functionals that send its elements to zero.

  \mytheorem{Annihilator structure}
  The annihilator of a subspace is a vector space.

  \mytheorem{Annihilator dimension}
  If a vector space is finite-dimensional, the dimension of the annihilator of a subspace is the difference
  between the dimensions of the whole space and subspace respectively.

  \mytheorem{Conditions for trivial annihilator}
  The annihilator is trivial if and only if the subspace is the whole space.
  The annihilator is the whole space if and only if the subspace is trivial.

  \mytheorem{Null space of a dual map}
  If the map acts upon finite-dimensional vector spaces
  the kernel of the dual map is the annihilator of the range of the map.
  The dimension of the kernel of the dual map is the dimension of the kernel
  of the map pluse the dimension of the codomain minus the dimension of the domain.
  
  \mytheorem{Cross dual properties properties}
  If the map acts between finite-dimensional vector spaces then the map is subspace if and only if its dual is injective.

  \mytheorem{The range of the dual}
  If the map acts between finite-dimensional vector spaces then the dimension of the range of the map and of its dual is equal,
  the range of the dual is equal to the annihilator of the kernel of the map.

  \mytheorem{Cross dual properties properties}
  If the map acts between finite-dimensional vector spaces then the map is injective if and only if its dual is surjective.

  \mytheorem{Matrix of the dual}
  If the map acts between finite-dimensional vector spaces, the matrix of the map dual is the transpose of the matrix of the map.
  
  \mytheorem{Row-column rank}
  The column rank of a matrix \textit{equals} its row rank.

  \mysection{Polynomials}
  \mydefinition{Real/immaginary part}
  \mydefinition{Complex conjugate}
  \mydefinition{Absolute value}
  \mytheorem{Properties of complex numbers}
  \mydefinition{Zero of a polynomial}
  \mytheorem{One-degree factoring}
  Each zero of a polynomial corresponds to a degree-one factor.
  \mytheorem{Count of zeros}
  \mytheorem{Division algorithm}
  \mytheorem{Fundamental theorem of algebra}
  \myparagraph{First version}
  \myparagraph{Second version}
  \mytheorem{Complex pairs of zeros}
  \mytheorem{Factorization of a quadratic polynomial}
  \mytheorem{Factorization of a real polynomial}
  
  
  
\end{multicols}

\end{document}
