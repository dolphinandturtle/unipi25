\include{packages}
\include{definitions}
\usepackage[english]{babel}

\begin{document}
\section*{``Linear Algebra Done Right (4th edition)'' by Sheldon Axler}
\begin{multicols}{3}
  1) Linear algebra, the study of linear maps on finite-dimensional vector
  spaces. Complex numbers are needed for some theorems.
  2) Complex numbers purpose, intuition and definition motivated by it.
  3) Properties of complex arithmetic, commutativity proof.
  4) Complex subtraction and division. Field as an alias and scalar power.
  5) Low dimension sets geometry. List definition, notation and difference from
  sets.
  6) Coordinate space definition, geometric intuition limit and coordinate
  addition definition.
  7) Commutativity of coordinate addition, coordinate notation expansion and
  shorthand for additive identity.
  8) Geometric properties of vectors and adding geometrically in $\reals^2$.
  9) Coordinate additive inverse definition and its geometric interpretation in
  $\reals^2$, coordinates scalar multiplication motivation, definition and
  scaling geometrically in $\reals^2$.
  10) Digression on fields, small field and relevance of fields in theorems.
  12) Vector spaces, extracting operation properties from coordinate spaces.
  Addition, scalar multiplication, vector space and vector definitions.
  13) Field choice over scalar multiplication. Fixed field vector spaces.
  coordinate space and sequence space as vector spaces. Set of functions notation
  and operation definition.
  14) Set of functions as vector spaces. Unique additive identity for vector
  spaces.
  15) Unique additive inverse for vector spaces, vector inverse notations,
  vector space absorbent scalar.
  16) Vector space absorbent vector, vector space scalar inversion.
  18) Subspace definition and conditions for it.
  19) Subspace examples, linearity of calculus, subspaces of $\reals^2$ and
  $\reals^3$ . Definition of sum of subspaces.
  20) Sum of subspaces examples.
  21) Sum of subspaces is the smallest containing subspace. Definition of direct
  sum and example.
  22) Example and counter examples for direct sums.
  23) Condition for a direct sum. Direct sum of two subspaces.
  24) Direct sum of multiple subspaces.
  27) Finite-dimensional vector spaces.
  28) List of vectors notation. Definition of linear combination and example.
  29) Definition of span and example. Span is the smallest containing subspace.
  Definition of spanning.
  30) Spanning coordinate space. Definition of finite-dimensional vector space.
  Definition of polynomial space and vector structure and unique coefficients.
  31) Definition of degree of polynomial. Definition of m-polynomial space.
  Definition of infinite-dimensional vector space, like polynomial space.
  Motivating linear indipendence
  32) Definition of linear independence and examples.
  33) Definition of linear dependence and examples. Linear dependence lemma.
  34) Linear dependence lemma edge case and example.
  35) Lenght of linearly independent list greater then lenght of spanning list.
  36) Lenght of vector lists examples. Finite-dimensional subspaces.
  39) Definition of basis and examples. Criterion for basis.
  40) Every spanning list contains a basis.
  41) Basis of finite-dimensional vector space. Every linearly independent list
  extends to a basis.
  42) Every subspace is part of a direct sum equal to the entire space.
  44) Intuition for dimension following coordinate space standard basis.
  Basis lenght does not depend on basis. Definition of dimension and examples.
  45) Dimension of a subspace. Linearly independent list of the right lenght is a
  basis. Subspace of full dimension equals the whole space.
  46) Basis for linearly independent list examples. Spanning list of the right
  lenght is a basis.
  47) Dimension of a sum.
  48) Comparing finite sets with finite-dimensional vector spaces.
  51) Correspondence between linear maps and matrices.
  52) Definition, notation and examples for linear map.
  53) More examples for linear maps.
  54) Linear map lemma.
  55) Definition of addition and scalar multiplication between linear maps.
  The linear map space is a vector space. Definition of product of linear maps.
  56) Algebraic properties of products of linear maps with examples. An linear
  maps takes zero to zero.
  59) Definition and examples of null space. The null space is a subspace.
  60) Definition of injective. Injectivity is equivalent to null space with
  only zero.
  61) Definition and examples of range. The range is a subspace.
  62) Definition and example of surjective. The fundamental theorem of linear
  maps.
  63) Linear map to a lower-dimensional space is not injective and example.
  64) Linear map to a higher-dimensional space is not surjective. Expressing
  systems of linear equations in term of linear maps.
  65) Homogeneous system of linear equations. System of linear equations with
  more equations than variables.
  69) Definition and example of matrix. Definition of matrix of a linear map.
  70) Matrix construction, standard basis and examples.
  71) Definition of matrix addition. Matrix of the sum of linear maps.
  Definition of scalar multiplication of a matrix.
  72) Example of addition and scalar multiplication on matrix. The matrix of a
  scalar times a linear map. Notation for m-by-n matrix space. Dimension of a
  matrix. Motivation for matrix multiplication.
  73) Definition and example of matrix multiplication.
  74) Matrix of product of linear maps. Notation for matrix rows and columns
  and example of usage.
  75) Entry of matrix product equals row times column. Column of matrix product
  equals matrix times column. Motivation for matrix product as linear
  combination.
  76) Linear combination of columns. Hint for linear combination of rows and
  developing tools to proove the column-row factorization. Matrix
  multiplication as linear combinations of columns or rows.
  77) Definition and examples of column rank and row rank. Definition of
  transpose of a matrix.
  78) Example of transpose of a matrix. Column-row factorization. Column rank
  equals row rank.
  79) Definition of rank.
  82) Definition of invertible and inverse linear map. Inverse is unique.
  Notation and example for inverse matrix.
  83) Invertibility equals injectivity and surjectivity.
  84) Counter-examples for invertibility. Injectivity is equivalent to
  surjectivity for linear maps between same finite-dimensional vector spaces.
  85) Example for injectivity-surjectivity equivalence. Inverse matrix
  commutativity over base matrix.
  86) Definition of isomorphism and isomorphic. Isomorphism seen as set
  relabeling. Dimensions shows whether vector spaces are isomorphic.
  87) Isomorphism between vector spaces and coordinate spaces based of their
  dimension. Linear transformations are isomorphic to matrices. Dimension of
  linear transformations.
  88) Definition and example of matrix of a vector. Relabeling elements of a
  vector space once a basis is chosen.
  89) The column of a matrix is a transformed basis. Linear maps act like
  matrix multiplication. Matrices induce linear maps from a vector matrix space
  to another. Chosen a basis every linear map can be seen as a matrix
  multiplication operation.
  90) Dimension of the range of a transformation equals the rank of the matrix
  of that transformation. For linear maps from a vector space to itself we
  usually use the same input and output basis. Definition of identity matrix.
  91) Lax notation for identity operator and matrix. Definition of invertible
  and inverse matrix. Uniqueness of the inverse matrix and inverse of the
  product. Matrix of product of linear maps.
  92) Matrix of identity operator with respect to two bases and example.
  93) Change-of-basis formula. Matrix of inverse equals inverse of matrix.
\end{multicols}

\pagebreak

\mychapter{Propositions}

\begin{multicols}{3}
  \mysection{Vector spaces}

  \mydefinition{Complex numbers}
  Ordered pairs of real numbers with addition and multiplication rules.
  Informally represented as a sum between a scalar and a scaled root of the negative scalar unit.
  Addition and multiplication rules are consistent with the informal definition.

  \mytheorem{Properties of complex arithmetic}
  Commutativity, associativity, identities, inverses and distributive.

  \mydefinition{Complex subtraction and division}
  Subtracting and dividing are respectively adding and multiplying by the respective inverse.

  \mydefinition{List of lenght}
  An ordered finite set with n elements.

  \mydefinition{N-Coordinate space}
  The set of scalar lists of lenght N.
  \myparagraph{Addition} Element-wise addition.
  \myparagraph{Additive identity} List of zeros.
  \myparagraph{Additive inverse} List with elements of opposite sign.
  \myparagraph{Scalar multiplication} List of scaled elements.

  \mydefinition{Vector operations}
  Addition on a set maps element pairs into an element.
  Scalar multiplication maps scalar, element pairs into an element.

  \mydefinition{Vector space}
  An abelian group under addition whose scalar multiplication defines a ring homomorphism
  from its associated field into the endomorphism ring of the group.

  \mysection{Subspaces}
  \mydefinition{Subspace}
  A subset of a vector space that is also a vector space with the same additive identity, addition, and scalar multiplication.

  \mytheorem{Conditions for a subspace}
  A subset of a vector space is a subspace if and only if it contains the additive identity and is closed under addition and scalar multiplication.

  \mydefinition{Sum of subspaces}
  The set of all the possible sums between elements of distinct subspaces.
  
  \mytheorem{Smallest subspace containing subspace}
  The sum of subspaces is the smallest subspace containing them individually.
  
  \mydefinition{Direct sum}
  A sum of subspaces whose elements can be written as a unique sum.
  
  \mytheorem{Linear condition for direct sum}
  A sum of subspaces is direct if and only if its null vector can be written as a unique sum of null vectors.

  \mytheorem{Set condition for direct sum}
  A sum between a pair of subspaces is direct if and only if their intersection is trivial.

  \mysection{Span and linear independence}
  \mydefinition{Linear combination}
  A sum over a list of vectors each individually scaled by some value.
  
  \mydefinition{Span}
  The set of all linear combinations of a list of vectors.
  
  \mytheorem{Smallest vector containing subspace}
  The span of a list of vectors is the smallest subspace containing them.

  \mydefinition{Polynomial with scalar coefficients}
  A function mapping field elements into themselves by summing coefficients multiplied by the element raised to the power of the coefficient's index.
  
  \mydefinition{Degree of a polynomial}
  The greatest index of a non-zero coefficient.
  
  \mydefinition{Vector space cardinality}
  \paragraph{\textbf{Finite-dimensional}}
  A vector space spanned by some list of vectors.
  \paragraph{\textbf{Infinite-dimensional}}
  Not finite-dimensional.
  
  \mydefinition{Linear dependence}
  A list of vectors whose null linear combination implies all coefficients to be zero is \textit{linearly independent},
  if not then \textit{linearly dependent}.

  \mytheorem{Linear dependence lemma}
  Some in a linearly dependent list of vectors are in the span of their preceding, they don't affect the first span.
  
  \mytheorem{List lenght constraint}
  In a finite-dimensional vector space, the lenght of a linearly independent list cannot be greater than that of a spanning list.
  
  \mytheorem{Finite-dimensional subspace}
  A subspace of a finite-dimensional vector space is finite-dimensional.
  
  \mysection{Bases}
  \mydefinition{Basis of a vector space}
  A list of vectors that is linearly independent and that spans their vector space.
  
  \mytheorem{Criterion for basis}
  A list of vectors is a basis if and only if every other vector can be written as a unique linear combination of it.
  
  \mytheorem{List resizing to a basis}
  \paragraph{\textbf{Reduction}}
  Spanning lists of vectors can be reduced to a basis.
  \paragraph{\textbf{Extension}}
  Linearly independent lists of vectors, in a finite-dimensional vector space, can be extended to a basis.

  \mytheorem{Finite-dimensional vector space basis}
  Finite-dimensional vector spaces have a basis.
  
  \mytheorem{Subspace direct completion}
  For every subspace, in a finite-dimensional vector space there exists a complement such that their direct sum equals the whole space.
  
  \mysection{Dimension (finite)}
  \mytheorem{Basis lenght lemma}
  Any pair of bases of a vector space have the same lenght.
  
  \mydefinition{Dimension of a vector space}
  The lenght of any basis of the vector space.
  
  \mytheorem{Dimension of a subspace}
  The dimension of a subspace cannot be greater than the dimension of the whole space.
  
  \mytheorem{Full dimension subspace}
  A subspace whose dimension is equal to that of its whole space, is the whole space itself.
  
  \mytheorem{Basis lenght list}
  A list of vectors whose lenght is equal to the full dimension and is linearly independent or spanning, is also a basis.
  
  \mytheorem{Dimension of a sum}
  The dimension of the sum between a pair of subspaces is the sum of their dimensions minus the dimension of their intersection.

  \mysection{Linear maps}
  \mydefinition{Linear map}
  An additive and homogeneous map between two vector spaces.

  \mytheorem{Linear map lemma}
  Elements of a basis can be linearly mapped to anything, and the map is unique.

  \mydefinition{Linear map vector operations}
  The sum of maps gives the sum of the mappings and the scaled map gives the mapping scaled.
  
  \mytheorem{Linear maps space structure}
  The space of linear maps with map addition and scalar multiplication is a vector space.

  \mydefinition{Product of linear maps}
  The product of maps gives the multiplier mapping of the multiplicand mapping.

  \mytheorem{Algebraic properties of products of linear maps}
  Associativity, identity and distributivity with addition.

  \mytheorem{Mapped null}
  Null vectors are linearly mapped into themselves.

  \mydefinition{Null space}
  The set of elements mapped into null by a given linear map.

  \mytheorem{Null space structure}
  The null space is a subspace of the domain of a linear map.

  \mydefinition{Injective}
  A map whose distinct elements are distinctly mapped.

  \mytheorem{Injective linear map}
  A linear map is injective if and only if the null space is trivial.

  \mydefinition{Range}
  The set of elements mapped by a given linear map.

  \mytheorem{Range structure}
  The range is a subspace of the codomain of a linear map.

  \mydefinition{Surjective}
  A map whose range equals its codomain.

  \mytheorem{Fundamental theorem}
  A linear map's domain dimension is equal to the sum between the dimensions of its null space and range.

  \mytheorem{Linear maps dimension}
  A linear mapping into a lower dimension is not injective, while into a higher dimension is not surjective.

  \mytheorem{Solution of linear systems}
  \paragraph{\textbf{Homogeneous}}
  A system of linear equations with more variables than equations and null costant terms, has non-zero solutions.
  
  \paragraph{\textbf{Eterogeneous}}
  A system of linear equations with more equation than variables has no solution for some choice of constant terms.
  
  \mysection{Matrices}
  \mydefinition{Matrix}
  A list of \textit{row} and \textit{column} lists of scalars referenced by a respective pair of coefficients.
  
  \mydefinition{Linear map matrix form}
  A matrix with each column related to a domain basis element, whose mapping can be expressed as a linear combination of the codomain basis with column entries as its coefficients.

  \mydefinition{Matrix vector operations}
  \myparagraph{Addition}
  For equal size matrices, the matrix with corresponding entries added.
  \myparagraph{Scalar multiplication}
  The matrix with its entries scaled.
  
  \mytheorem{Matrix of a linear map vector operation}
  Matrix form distributes over linear map operations.
  
  \mytheorem{Matrix space structure}
  The space of matrices of a given size with matrix addition and scalar multiplication is a vector space.
  
  \mytheorem{Dimension of a matrix}
  The number of rows times the number of columns.
  
  %\mydefinition{Matrix multiplication}
  %Left fixed row, left moving column, right moving row, right fixed column.
  %
  %\mytheorem{Matrix of product of linear maps}
  %The matrix of the product of linear maps is the product of matrices of the linear maps.
  %
  %\mydefinition{Row and column}
  %By fixing a row index or a column index separately, a matrix can be respectively reduced to either a row or a column.
  %
  %\mytheorem{Matrix multiplication characterizations}
  %\paragraph{\textbf{Row column product}}
  %\paragraph{\textbf{Matrix times row/column}}
  %\paragraph{\textbf{Linear combination of rows/columns}}
  %
  %\mytheorem{Linear combination rows/columns}
  %
  %\mydefinition{Column/row rank}
  %
  %\mydefinition{Matrix transpose}
  %
  %\mytheorem{Column-row factorization}
  %
  %\mytheorem{Column rank equals row rank}
  %
  %\mydefinition{Rank}
  %
  %\mysection{Invertibility and isomorphisms}
  %
  %\mydefinition{Linear map inverse}
  %
  %\mytheorem{Inverse uniqueness}
  %
  %\mytheorem{Invertibility criterion}
  %
  %\mytheorem{Injectivity and surjectivity equivalence}
  %
  %\mytheorem{Identity map product}
  %
  %\mydefinition{Isomorphism}
  %Invertible linear map.
  %
  %\mytheorem{Isomorphic dimension}
  %A pair of finite-dimensional vector spaces are isomorphic if and only if their dimension is equal.
  %
  %\mytheorem{Linear map isomorphism}
  %
  %\mytheorem{Linear map dimension}
  %
  %\mydefinition{Matrix of a vector}
  %
  %\mytheorem{Columns of matrix as matrix of a vector}
  %
  %\mytheorem{Linear maps as matrix multiplications}
  %
  %\mytheorem{Range dimension on matrix}
  %
  %\mydefinition{Identity matrix}
  %
  %\mydefinition{Inverse matrix}
  %
  %\mytheorem{Matrix of product of linear maps}
  %
  %\mytheorem{Identity matrix with bases}
  %
  %\mytheorem{Change-of-basis formula}
  %
  %\mytheorem{Matrix of inverse}

\end{multicols}

\end{document}
