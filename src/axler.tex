\include{packages}
\include{definitions}
\usepackage[english]{babel}

\begin{document}
\section*{``Linear Algebra Done Right (4th edition)'' by Sheldon Axler}
\begin{multicols}{3}
  1) Linear algebra, the study of linear maps on finite-dimensional vector
  spaces. Complex numbers are needed for some theorems.
  2) Complex numbers purpose, intuition and definition motivated by it.
  3) Properties of complex arithmetic, commutativity proof.
  4) Complex subtraction and division. Field as an alias and scalar power.
  5) Low dimension sets geometry. List definition, notation and difference from
  sets.
  6) Coordinate space definition, geometric intuition limit and coordinate
  addition definition.
  7) Commutativity of coordinate addition, coordinate notation expansion and
  shorthand for additive identity.
  8) Geometric properties of vectors and adding geometrically in $\reals^2$.
  9) Coordinate additive inverse definition and its geometric interpretation in
  $\reals^2$, coordinates scalar multiplication motivation, definition and
  scaling geometrically in $\reals^2$.
  10) Digression on fields, small field and relevance of fields in theorems.
  12) Vector spaces, extracting operation properties from coordinate spaces.
  Addition, scalar multiplication, vector space and vector definitions.
  13) Field choice over scalar multiplication. Fixed field vector spaces.
  coordinate space and sequence space as vector spaces. Set of functions notation
  and operation definition.
  14) Set of functions as vector spaces. Unique additive identity for vector
  spaces.
  15) Unique additive inverse for vector spaces, vector inverse notations,
  vector space absorbent scalar.
  16) Vector space absorbent vector, vector space scalar inversion.
  18) Subspace definition and conditions for it.
  19) Subspace examples, linearity of calculus, subspaces of $\reals^2$ and
  $\reals^3$ . Definition of sum of subspaces.
  20) Sum of subspaces examples.
  21) Sum of subspaces is the smallest containing subspace. Definition of direct
  sum and example.
  22) Example and counter examples for direct sums.
  23) Condition for a direct sum. Direct sum of two subspaces.
  24) Direct sum of multiple subspaces.
  27) Finite-dimensional vector spaces.
  28) List of vectors notation. Definition of linear combination and example.
  29) Definition of span and example. Span is the smallest containing subspace.
  Definition of spanning.
  30) Spanning coordinate space. Definition of finite-dimensional vector space.
  Definition of polynomial space and vector structure and unique coefficients.
  31) Definition of degree of polynomial. Definition of m-polynomial space.
  Definition of infinite-dimensional vector space, like polynomial space.
  Motivating linear indipendence
  32) Definition of linear independence and examples.
  33) Definition of linear dependence and examples. Linear dependence lemma.
  34) Linear dependence lemma edge case and example.
  35) Lenght of linearly independent list greater then lenght of spanning list.
  36) Lenght of vector lists examples. Finite-dimensional subspaces.
  39) Definition of basis and examples. Criterion for basis.
  40) Every spanning list contains a basis.
  41) Basis of finite-dimensional vector space. Every linearly independent list
  extends to a basis.
  42) Every subspace is part of a direct sum equal to the entire space.
  44) Intuition for dimension following coordinate space standard basis.
  Basis lenght does not depend on basis. Definition of dimension and examples.
  45) Dimension of a subspace. Linearly independent list of the right lenght is a
  basis. Subspace of full dimension equals the whole space.
  46) Basis for linearly independent list examples. Spanning list of the right
  lenght is a basis.
  47) Dimension of a sum.
  48) Comparing finite sets with finite-dimensional vector spaces.
  51) Correspondence between linear maps and matrices.
  52) Definition, notation and examples for linear map.
  53) More examples for linear maps.
  54) Linear map lemma.
  55) Definition of addition and scalar multiplication between linear maps.
  The linear map space is a vector space. Definition of product of linear maps.
  56) Algebraic properties of products of linear maps with examples. An linear
  maps takes zero to zero.
  59) Definition and examples of null space. The null space is a subspace.
  60) Definition of injective. Injectivity is equivalent to null space with
  only zero.
  61) Definition and examples of range. The range is a subspace.
  62) Definition and example of surjective. The fundamental theorem of linear
  maps.
  63) Linear map to a lower-dimensional space is not injective and example.
  64) Linear map to a higher-dimensional space is not surjective. Expressing
  systems of linear equations in term of linear maps.
  65) Homogeneous system of linear equations. System of linear equations with
  more equations than variables.
  69) Definition and example of matrix. Definition of matrix of a linear map.
  70) Matrix construction, standard basis and examples.
  71) Definition of matrix addition. Matrix of the sum of linear maps.
  Definition of scalar multiplication of a matrix.
  72) Example of addition and scalar multiplication on matrix. The matrix of a
  scalar times a linear map. Notation for m-by-n matrix space. Dimension of a
  matrix. Motivation for matrix multiplication.
  73) Definition and example of matrix multiplication.
  74) Matrix of product of linear maps. Notation for matrix rows and columns
  and example of usage.
  75) Entry of matrix product equals row times column. Column of matrix product
  equals matrix times column. Motivation for matrix product as linear
  combination.
  76) Linear combination of columns. Hint for linear combination of rows and
  developing tools to proove the column-row factorization. Matrix
  multiplication as linear combinations of columns or rows.
  77) Definition and examples of column rank and row rank. Definition of
  transpose of a matrix.
  78) Example of transpose of a matrix. Column-row factorization. Column rank
  equals row rank.
  79) Definition of rank.
  82) Definition of invertible and inverse linear map. Inverse is unique.
  Notation and example for inverse matrix.
  83) Invertibility equals injectivity and surjectivity.
  84) Counter-examples for invertibility. Injectivity is equivalent to
  surjectivity for linear maps between same finite-dimensional vector spaces.
  85) Example for injectivity-surjectivity equivalence. Inverse matrix
  commutativity over base matrix.
  86) Definition of isomorphism and isomorphic. Isomorphism seen as set
  relabeling. Dimensions shows whether vector spaces are isomorphic.
  87) Isomorphism between vector spaces and coordinate spaces based of their
  dimension. Linear transformations are isomorphic to matrices. Dimension of
  linear transformations.
  88) Definition and example of matrix of a vector. Relabeling elements of a
  vector space once a basis is chosen.
  89) The column of a matrix is a transformed basis. Linear maps act like
  matrix multiplication. Matrices induce linear maps from a vector matrix space
  to another. Chosen a basis every linear map can be seen as a matrix
  multiplication operation.
  90) Dimension of the range of a transformation equals the rank of the matrix
  of that transformation. For linear maps from a vector space to itself we
  usually use the same input and output basis. Definition of identity matrix.
  91) Lax notation for identity operator and matrix. Definition of invertible
  and inverse matrix. Uniqueness of the inverse matrix and inverse of the
  product. Matrix of product of linear maps.
  92) Matrix of identity operator with respect to two bases and example.
  93) Change-of-basis formula. Matrix of inverse equals inverse of matrix.
\end{multicols}

\pagebreak

\mychapter{Propositions}

\begin{multicols}{3}
  \mysection{Vector spaces}

  \mydefinition{Complex numbers}
  Ordered pairs of real numbers with addition and multiplication rules consistent with
  the algebra of a sum between a number and a scaled \textit{root of the negative unit}.

  \mytheorem{Properties of complex arithmetic}
  Commutativity, associativity, identities, inverses and distributive.

  \mydefinition{Complex subtraction and division}
  Subtracting and dividing are respectively adding and multiplying by the respective \textit{inverse}.

  \mydefinition{List of lenght}
  A \textit{finite} set with an \textit{ordering}.

  \mydefinition{Coordinate space}
  The set of scalar lists of a given lenght.

  \mydefinition{Coordinate addition}
  A map from a list pair into a list with \textit{corresponding elements added}.

  \mydefinition{Coordinate identity}
  List of \textit{zeros}.

  \mydefinition{Coordinate inverse}
  A list endo-map that inverts the \textit{sign} of each element.

  \mydefinition{Coordinate scaling}
  A map from a scalar and list pair into a list with each element scaled.

  \mydefinition{Vector addition}
  A map from a space to \textit{its} endomorphisms.
  \mydefinition{Vector scalar multiplication}
  A map from a \textit{field} to the endomorphisms of a space.

  \mydefinition{Vector space}
  An \textit{abelian group} under addition with a \textit{ring homomorphism} from a \textit{field} into the group's \textit{endomorphism ring} as scalar multiplication.

  \mydefinition{Vector}
  An \textit{element} of a vector space.

  \mydefinition{Standard vector spaces}
  A \textit{real vector space's} scalar multiplication is over the \textit{reals},
  a \textit{complex vector space's} scalar multiplication is over the \textit{complexes}.

  \mytheorem{Vector space properties}
  Identity and inverses are unique. Null scaling and scaling null is null. Identity inverse scaling is inverse.

  \mysection{Subspaces}
  \mydefinition{Subspace}
  A subset of a vector space that is also a vector space with the same \textit{additive identity} and \textit{operations}.

  \mytheorem{Conditions for a subspace}
  A subset of a vector space is a subspace if and only if it contains the additive identity and is \textit{closed} under the operations.

  \mydefinition{Sum of subspaces}
  The set of all \textit{sums between elements} of distinct subspaces.
  
  \mytheorem{Smallest subspace containing subspace}
  The sum of subspaces is the smallest subspace containing them individually.
  
  \mydefinition{Direct sum}
  A sum of subspaces whose elements can be written as a \textit{unique sum}.
  
  \mytheorem{Linear condition for direct sum}
  A sum of subspaces is direct if and only if its \textit{null vector} can be written as a unique sum of null vectors.

  \mytheorem{Set condition for direct sum}
  A sum between a pair of subspaces is direct if and only if their \textit{intersection is trivial}.

  \mysection{Span and linear independence}
  \mydefinition{Linear combination of vectors}
  A \textit{sum} over a list of vectors each individually \textit{scaled} by some value.
  
  \mydefinition{Span}
  The set of all \textit{linear combinations} of a list of vectors.
  
  \mytheorem{Smallest vector containing subspace}
  The span of a list of vectors is the smallest subspace containing them.

  \mydefinition{Polynomial with scalar coefficients}
  A field endo-map that sums over elements raised to increasing \textit{whole powers} and \textit{scaled} by some value.
  
  \mydefinition{Degree of a polynomial}
  The \textit{greatest power} taken on an element not scaled by zero.
  
  \mydefinition{Cardinality}
  A vector space \textit{spanned} by some list of vectors is \textit{finite-dimensional}, if not then \textit{infinite-dimensional}.
  
  \mydefinition{Linear dependence}
  A list of vectors whose null linear combination implies all coefficients to be zero is \textit{linearly independent},
  if not then \textit{linearly dependent}.

  \mytheorem{Linear dependence lemma}
  Some in a linearly dependent list of vectors are in the span of their preceding, \textit{they don't affect the first span}.
  
  \mytheorem{List lenght constraint}
  In a finite-dimensional vector space, the lenght of a linearly independent list \textit{cannot be greater} than that of a spanning list.
  
  \mytheorem{Finite-dimensional subspace}
  A subspace of a finite-dimensional vector space is finite-dimensional.
  
  \mysection{Bases}
  \mydefinition{Basis of a vector space}
  A list of vectors that is linearly \textit{independent} and that \textit{spans} their vector space.
  
  \mytheorem{Criterion for basis}
  A list of vectors is a basis if and only if every other vector can be written as a \textit{unique linear combination} of it.
  
  \mytheorem{List resizing to a basis}
  Spanning lists of vectors can be \textit{reduced} to a basis. Linearly independent lists of vectors, in a finite-dimensional
  vector space, can be \textit{extended} to a basis.

  \mytheorem{Finite-dimensional vector space basis}
  Finite-dimensional vector spaces have a basis.
  
  \mytheorem{Subspace direct completion}
  For every subspace, in a finite-dimensional vector space there exists a \textit{complement} such that their direct sum equals the whole space.
  
  \mysection{Dimension (finite)}
  \mytheorem{Basis lenght lemma}
  Any pair of bases of a vector space have the \textit{same lenght}.
  
  \mydefinition{Dimension of a vector space}
  The \textit{lenght} of any basis of the vector space.
  
  \mytheorem{Dimension of a subspace}
  The dimension of a subspace \textit{cannot be greater} than the dimension of the whole space.
  
  \mytheorem{Full dimension subspace}
  A subspace whose dimension is \textit{equal} to that of its whole space, is the whole space itself.
  
  \mytheorem{Basis lenght list}
  A list of vectors whose lenght is equal to the full dimension and is linearly independent or spanning, is also a basis.
  
  \mytheorem{Dimension of a sum}
  The dimension of the sum between a pair of subspaces is the sum of their dimensions minus the dimension of their intersection.

  \mysection{Linear maps}
  \mydefinition{Linear map}
  A group endomorphism over addition that commutes with scalar multiplication.

  \mytheorem{Linear map lemma}
  Elements of a basis can be linearly mapped to anything, and the map is unique.

  \mydefinition{Linear map vector operations}
  Map addition and scalar multiplication is \textit{pointwise}.
  
  \mytheorem{Linear maps space structure}
  The space of linear maps with map addition and scalar multiplication is a \textit{vector space}.

  \mydefinition{Product of linear maps}
  The product of maps gives their \textit{composition}.

  \mytheorem{Algebraic properties of products of linear maps}
  Associativity, identity and distributivity over addition.

  \mytheorem{Mapped null}
  Null vectors are linearly mapped into themselves.

  \mydefinition{Null space}
  The set of elements mapped into \textit{null vectors} by a given linear map.

  \mytheorem{Null space structure}
  The null space is a \textit{subspace} of the domain of a linear map.

  \mydefinition{Injective}
  A map whose distinct elements are \textit{distinctly mapped}.

  \mytheorem{Injective linear map}
  A linear map is injective if and only if the null space is trivial.

  \mydefinition{Range}
  The set of elements \textit{mapped} by a given linear map.

  \mytheorem{Range structure}
  The range is a subspace of the \textit{codomain} of a linear map.

  \mydefinition{Surjective}
  A map whose range equals its codomain.

  \mytheorem{Fundamental theorem}
  A linear map's domain dimension is equal to the sum between the dimensions of its null space and range.

  \mytheorem{Linear maps dimension}
  In matters of dimension, higher isn't \textit{into} lower and lower isn't \textit{onto} higher.

  \mytheorem{Solution of linear systems}
  \paragraph{\textbf{Homogeneous}}
  A system of linear equations with more variables than equations and null costant terms, has \textit{non-zero solutions}.
  
  \paragraph{\textbf{Eterogeneous}}
  A system of linear equations with more equation than variables has \textit{no solution} for some choice of constant terms.
  
  \mysection{Matrices}
  \mydefinition{Matrix}
  A whole rectangle of numbers with a \textit{row-column} index pair.
  
  \mydefinition{Linear map matrix form}
  Each column represents a \textit{mapped domain basis} as a linear combination of \textit{codomain basis} with column coefficients.

  \mydefinition{Matrix addition}
  A map from a matrix pair into a matrix with \textit{corresponding elements added}.

  \mydefinition{Matrix scaling}
  A map from a scalar and matrix pair into a matrix with each element scaled.
  
  \mytheorem{Matrix of a linear map operation}
  Linear maps are \textit{homomorphic} to matrices over \textit{addition} and \textit{scalar multiplication}.
  
  \mytheorem{Matrix space structure}
  The space of matrices of a given size with matrix addition and scalar multiplication is a \textit{vector space}.
  
  \mytheorem{Dimension of a matrix}
  The number of rows times the number of columns.

  \mydefinition{Matrix multiplication}
  A map from a matrix pair into a matrix whose entries
  sum over the entrywise product of the entry's row and column.


  \mytheorem{Matrix of product of linear maps}
  Linear maps are \textit{homomorphic} to matrices over \textit{multiplication}.

  \mydefinition{Row and column matrices}
  Respectively, a matrix with \textit{one row} and a matrix with \textit{one column}.

  \mytheorem{Matrix multiplication characterizations}
  An entry from a matrix multiplication is a multiplication between row and column matrices of the entries.
  
  %\paragraph{\textbf{Row column product}}
  %\paragraph{\textbf{Matrix times row/column}}
  %\paragraph{\textbf{Linear combination of rows/columns}}
  %
  %\mytheorem{Linear combination rows/columns}
  %
  %\mydefinition{Column/row rank}
  %
  %\mydefinition{Matrix transpose}
  %
  %\mytheorem{Column-row factorization}
  %
  %\mytheorem{Column rank equals row rank}
  %
  %\mydefinition{Rank}
  %
  %\mysection{Invertibility and isomorphisms}
  %
  %\mydefinition{Linear map inverse}
  %
  %\mytheorem{Inverse uniqueness}
  %
  %\mytheorem{Invertibility criterion}
  %
  %\mytheorem{Injectivity and surjectivity equivalence}
  %
  %\mytheorem{Identity map product}
  %
  %\mydefinition{Isomorphism}
  %Invertible linear map.
  %
  %\mytheorem{Isomorphic dimension}
  %A pair of finite-dimensional vector spaces are isomorphic if and only if their dimension is equal.
  %
  %\mytheorem{Linear map isomorphism}
  %
  %\mytheorem{Linear map dimension}
  %
  %\mydefinition{Matrix of a vector}
  %
  %\mytheorem{Columns of matrix as matrix of a vector}
  %
  %\mytheorem{Linear maps as matrix multiplications}
  %
  %\mytheorem{Range dimension on matrix}
  %
  %\mydefinition{Identity matrix}
  %
  %\mydefinition{Inverse matrix}
  %
  %\mytheorem{Matrix of product of linear maps}
  %
  %\mytheorem{Identity matrix with bases}
  %
  %\mytheorem{Change-of-basis formula}
  %
  %\mytheorem{Matrix of inverse}

\end{multicols}

\end{document}
