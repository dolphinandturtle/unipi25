\include{packages}
\include{definitions}

\begin{document}
\mychapter{Artificial intelligence}
\footnote{Sources: \href{https://youtu.be/qJeaCHQ1k2w?si=3jG7sa0t9ay1N441}{"Variational Autoencoders | Generative AI Animated" by Deepia}}
% I haven't looked through the ELBO derivation part 18:39.

\paragraph{\textbf{Keywords}}
Variational Auto Encoder (VAE), Latent space, Diederik Kingma, posterior distribution, likely-hood distribution, ELBO, reparameterization

\begin{multicols}{3}
  Autoencoders process data with lossy compression and then try to decompress the data, the compressed form of the data forms a mathematical space called \textit{latent space}.
  One could try to sample arbitrary from the compressed data in the latent space and then decode them, the results unfortunately are very different from the compressed data.
  Even if one tries to sample points in a neighbour of the representation of the compressed data, unforunately one comes to the same fate.
  Diederik Kingma, he studies deep learning and bayesian statistics, and in his paper ``Auto-encoding Variational Bayes'' came with a solution to this problem (he also did the
  Adam optimizer).
  We must first adopt some Baynesian notation: $X$ indicates a random variable, $x \sim X$ indicates sampling,  $p(x)$ is a probability density function,
  $\mathbb{E}[X]$ expectation value.
  We want new data from $p(x)$ generated by our dataset without knowing the exact properties of $p(x)$.
  To make it easier we work with $p(z)$ the \textit{latent distribution}, it captures the features of the data.
  \textit{Posterior distribution} $p(z|x)$ gives us the probability that a latent vector comes from a specific image.
  \textit{Likely-hood distribution} $p(x|z)$ gives us the probability that a specific image comes from a lantent vector.
  If we can sample latent vectors from $p(z|x)$ those latents are likely to have been generated by $p(x)$
  so we can recostruct these latents into images and by doing that we have generated new samples.
  We don't know the shape of latent distribution. We assume that it is a normal distribution otherwise we can't know $p(x|z)$.
  The variational part is in calculating $p(z|x)$, we approximate with the $q(z|x)$ gaussian with parameters $\mu$ and $\sigma$.
  The variational bayes method consists in training an encoder to estimate the $\mu$ and $\sigma$ parameters from images.
  Then a decoder to recosnstruct images from latent variables that come from the posterior distribution.
  The ``\textit{ELBO}'' training objective is expressed by
  \begin{equation*}
    L(x) =~
    \stackrel[\text{consistency}]{}{\mathbb{E}_{q(z|x)}[\log p(x|z)]} -
    \stackrel[\text{regularization}]{}{\text{KL}(q(z|x) | p(z))}
  \end{equation*}
  With a variational auto-encoders we transform input data into parameters of a gaussian distribution instead of a single point.
  We then sample points inside the latent distribution and decode them.
  The challenge however is now the backpropagation, which can be done with a the \textit{reparameterization trick}, with which we
  can solve the problem by means of ``ADAM'' optimization. We compress data, recostruct it, evaluate the loss and adjust the parameters.
  \paragraph{\textbf{Pros}}
  The interesting part of this model is that it can produce coherent data that it wasn't original trained on. Furthermore
  convext interpolation between data shows that the latent space has a form of continuity.
  \paragraph{\textbf{Cons}}
  VAES produce blurry images and lacks the capacity to add constraints on generated data.
  Some progress has been made with the introduction of CVAE's, beta-VAE and VQ-VAE.
\end{multicols}

\mychapter{Lie theory}
\footnote{Sources: \href{https://youtu.be/IlqVo3sJFLE?si=7Aa7z2ZbiFgRFJG6}{"Why study Lie theory? | Lie groups, algebras, brackets \#1" by Mathemaniac}}
\paragraph{\textbf{Keywords}}
Lie, Galois, differential equations, symmetries, physics.

\begin{multicols}{3}
  Sophus Lie studied differential equations and was in search of a unified theory to solve them much
  like the success of Galois theory on polynomials that relied on the use of symmetries.
  In the case of Galois his theory relied on so-called discrete symmetries permutations, while Lie would
  have to rely on continuous symmetries due to the nature of differential equation's solution structure.
  Unfortunately Lie's theory did not dominate the study of differential equations, and was used for rather
  different areas of science, in particular physics for the study of quantum mechanics from which one gets
  unexpected results that lead to objects like $1/2$ spins or the prediction of $\Omega^-$ Baryon.
\end{multicols}

\mychapter{Simulation algorithm (Barnes-Hut)}
\footnote{Sources: \href{https://youtu.be/nZHjD3cI-EU?si=MFS3zFu0WUgWJujP}{"How to make HUGE N-Body Simulations (N=1,000,000+)" by Deadlock}}

\paragraph{\textbf{Keywords}} Multipole expansion

\begin{multicols}{3}
  To simulate the gravitational interaction between a large amount of bodies.
  The direct sum implementation doesn't scale nicely because it is $O(n^2)$.
  With a \textit{multipole} expansion of the law of gravitation
  \begin{equation*}
    \begin{gathered}
      M = \sum_{i=1} ^N m_i \quad
      C = 1/M \sum_{i=1} ^N m_i r_i \\
      a = G \sum_{i=1}^N m_i \frac{r_i - r}{|r_i - r|^3} \implies a \approx GM \frac{C - r}{|C - r|^3}
    \end{gathered}
  \end{equation*}
  The more the group of bodies is compact the better it is for the approximation, evaluated by the error factor $s/d$,
  where $s$ is the size of the group and $d$ is the distance from its center of mass. When the error goes beyond a fixed threshold,
  we can split the active group into 4 subgroups acting on the body and repeating this process until the error factor is below the
  threshold. The \textit{quad-tree} datastructure is the perfect tool to implement this programmatically.
\end{multicols}


\mychapter{Perturbation theory to solve unsolvable physics problems}
\footnote{Sources:
  \href{https://youtu.be/j0zghSW6loQ?si=wMq23Hep2WyrlTQQ}
  {"The Theory that Solves "Unsolvable" Quantum Physics Problems - Perturbation Theory" by Parth G}}

\paragraph{\textbf{Keywords}} Quantum mechanics, Schrodinger equation, Perturbation theory

\begin{multicols}{3}
  Perturbation theory is used to solve ``unsolvable'' systems in quantum mechanics. Solving a system in quantum mechanics is analogous to solving
  a \textit{wave function} that contains all the information of the system. The wave function comes from the \textit{Schr\"odinger equations}.
  With kinetic and potential we can find allowed wave functions, however potentials are arbitrary functions that can quickly make the system unsolvable.
  However there are clever strategies to work out approximations even without the aid of a computer. \\
  
  \paragraph{\textbf{Idea}}
  By taking a system we already know how to solve and perturb it to match the form of our current one, we approximate a new solution deviating from the
  original solution of the previously solved system. \\

  If quantum system is a free particle in a potential well the particle is allowed to have a specific energy (quantization), and for each energy
  level there is a wave function. Now suppose in the middle of the well we add a small bump, the system is now different from the flat bottom well.
  Luckily the new energy levels and the wave functions deviate slightly from the known form.
  Lets then write the new system's hamiltonian as the old system hamiltonian with a variation term.
  \begin{equation*}
    \hat{H}_{\text{\text{new}}} = \hat{H}_0 + \gamma \alpha \delta (a/2)
  \end{equation*}
  when $\lambda$ is small we say
  \begin{equation*}
    \ket{\psi_{\text{new}}^n} = \ket{\psi_0^n} + \lambda \ket{\psi_1^n} + \lambda^2 \ket{\psi_2 ^n} + ...
  \end{equation*}
  also the energy changes
  \begin{equation*}
    \begin{gathered}
      E_{\text{new}}^n = E_0^n + \lambda E_1^n + ... \\
      E_1^n = \frac{\bra{\psi_0^n}\hat{V}_{\text{new}} \ket{\psi_0^n}}{\bra{\psi_0^n}\ket{\psi_0^n}}
    \end{gathered}
  \end{equation*}
  where $\bra{\psi_0^n} \hat{V}_{\text{new}} \ket{\psi_0^n}$ is the expectation value of the \textit{perturbation operator}
  when the system is in the unperturbated value.
\end{multicols}

\mychapter{Drawing exercises}
\footnote{Sources:
  \href{https://youtu.be/WUcYTAiCQyQ?si=vXJLxQDlKPPz1_AA}
  {"3 DRAWING EXERCISES THAT WILL CHANGE YOUR LIFE" by Marc Brunet}}
\begin{enumerate}
\item Volume rotation, drawing volumes like: cubes, cilinders and spheres, and rotate them.
\item Volume deformation, like twists bends, squishing and squashing.
\item Volume carving.
\end{enumerate}


\mychapter{Quantum mechanics classical generators}
\footnote{Sources:
  \href{https://youtu.be/lJorwy0BQGU?si=88H2V0VSIbd8cjyr}
  {"Ch 12: What are generators in classical mechanics? | Maths of Quantum Mechanics" by Quantum Sense}}

\begin{multicols}{3}
  Can some principles of quantum mechanics seen in the lagrangian framework of physics?
  In quantum mechanics the state holds all the information of a particle.
  In newtonian mechanics there is no such thing as a particle state and all of the ``observables'' are
  dynamic variables though of as an isolated function of time.

  How could we go on about building a classical state of a particle?
  Given the lagrangian framework, suppose the lagrangian function is given as:
  \begin{equation*}
    L = \frac{1}{2}m \dot{x}^2 - V(x)
  \end{equation*}

  The later development of the quantum path integrale is related to the classical concept of a Lagrangian.

  As an example the position function is a stationary point of an action as stated by the principle of least (or stationary) action.

  The form of the action can be extracted from the quantum path integral.

  The field of calculus of variations gives us the Euler-Lagrange equation, an expression consistent with Newton's second law of motion.
  Patterns in physics emerge from the Euler lagrange equation,
  changes in momentum seem connected to the changes of position in a state.
  \begin{equation*}
    \pdv{L}{x} = \dv{p}{t}
  \end{equation*}

  Conversely the kinetic term of the lagrangian can be expressed in terms of momentum:
  \begin{equation*}
    \pdv{L}{p} = \dv{x}{t}
  \end{equation*}

  For the change of time with the chain rule and Euler-Lagrange equation one further gets:
  \begin{equation*}
    \dv{t} L\left(t, x(t), \dot{x}(t)\right) \implies
    ... \implies
    \pdv{L}{t} = -\dv{E}{t}
  \end{equation*}

  Futher patern emerge from the change of rotation
  \begin{equation*}
    \pdv{L}{\theta} = \dv{l}{t}
  \end{equation*}

  The variation of the lagrangian relative to some parameter is tied to the a physical quantity changing in time.
  We then say that a certain that some parameter is the generator of a physical quanity, and study of generators
  is done through the study of Hamiltonian mechanics.

  All of this is relavent to quantum mechanics
  \begin{equation*}
    \begin{gathered}
      L \iff \ket{\psi} \\
      \pdv{L}{t} = -\dv{E}{t} \qquad
      \dv{\ket{\psi}}{t} \to \hat{E}
    \end{gathered}
  \end{equation*}

  One can than think that a change of the parallel of classical operators behave similarly on state meaning:
  \begin{equation*}
    \hat{p} \to \dv{x} \qquad
    \hat{x} \to \dv{p}
  \end{equation*}
\end{multicols}


\mychapter{Viscosity}
\footnote{Sources: \href
  {https://youtu.be/VvDJyhYSJv8?si=wjiCjc7eXkeC40rm}
  {"Understanding Viscosity" by The Efficient Engineer}
}

\begin{multicols}{3}
  It is helpful to think of fluid as flowing through separate layers, due to natural abbrasion it logical to consider
  the shear stress between thes layers.
  The barrier in which a fluid is contained infers the no-slip condition, which is what causes the characteristic slope
  of the fluid velocity profile, close to the wall the velocity changes very fast.
  Fluid viscosity $\mu$ is the linear relationship coefficient between shear stress $\tau$ and velocity slope $\dv{u}{y}$,
  and can be interpreted as its the internal friction of fluid in motion. Fluids which such a relation are called Newtonian
  as they adhere to the following Newton's law of viscosity:
  \begin{equation*}
    \tau  = \mu \dv{u}{y}
  \end{equation*}
  the relationship between dynamic viscosity $\nu$ and fluid viscosity is as follows ($\rho$ is the fluid density):
  \begin{equation*}
    \nu = \mu / \rho
  \end{equation*}
  A flowing fluid element is deformed by a shear because the upper surface moves faster than the lower surface,
  and the shear strain can be calculated from
  \begin{equation*}
    \dot{\gamma} = \frac{\Delta u}{\Delta y}
  \end{equation*}
  By combining the previous relation with Newton's law of viscosity, the resulting expression's form reminds us of
  Hooke's law, but in this case for fluids, where the strain rate is the dynamic variable instead of strain itself.
  \begin{equation*}
    \tau = \mu \dot{\gamma}
  \end{equation*}
  Fluid viscosity and dynamic viscosity is measured in Poise and Stokes.
  Fluids and gasses behave differently on a molecular level. Fluid viscosity is a physical model that emerges from
  cohesive forces between molecules. Gas viscosity instead from the kinematic collisions between fast moving free particles.
  Moreover the viscosity of a fluid increases with the decreasing of temperature, while for gases their viscosity increases
  by also increasing their temperature (more collisions happen). Models have been made to describe this phenomena such as:
  \paragraph{\textbf{Andrade's equation for fluids}}
  \begin{equation*}
    \mu = Ae^{B/T}
  \end{equation*}
  \paragraph{\textbf{Sutherland's equation for gases}}
  \begin{equation*}
    \mu = \frac{A\sqrt{T}}{1 + b/T}
  \end{equation*}
  (viscosity also varies with pressure but a much weaker dependence)
  Reynolds number, the indicator of laminar flow, is related to the fluids viscosity.
  Viscosity is the reason behind pressure drops, and makes finding solutions to systems of equations sometimes ``impossible'',
  luckily the theory shows that outside the \textit{boundary layer}, it is possible to ignore the ignore viscous contribute
  to the equations, partitioning the space into two regions: the \textit{viscous region} and \textit{inviscid region}.
  Clearly this cannot be done while studying the flow of air on a plane wing, but can be done in some macroscopic hydraulic systems
  The \textit{Navier-Stokes equations} are really hard to solve, but by ignoring the viscous forces we get the
  reduced form called \textit{Euler equations} that are easier to solve and from which we get the \textit{Bernoulli equations}.
  A common example of non-newtonian fluids is \textit{paint}, whose viscosity increases significantly when it forms a thin layer.
\end{multicols}

\mychapter{Reynolds transport theorem}
\footnote{Sources:
  \href{https://youtu.be/aglUE8-TO-o?si=WT6Oy8Z-3LUYDyUw}{"Reynolds Transport Theorem" by peteroshkai},
  \href{https://youtu.be/B-ARVMoCu5M?si=_7e1dNTfakasU9mH}{"Conceptual schematics in fluid mechanics" by peteroshkai}
}

\paragraph{\textbf{Keywords}} Material derivative, conservation of mass, gauss divergence, flux, incompressible flow.
\begin{multicols}{3}
  \paragraph{\textbf{Lagrangian description of fluid}}
  Write the conservation laws for a material volume.
  \paragraph{\textbf{Eulerian/spacial description of fluid}}
  Describe the conservations law for a volume fixed in space with material going through it. \\

  The Reynold transport theorem reconciles both description for when the volume coincides.
  If we consider a control volume fixed in space, and write $\tilde{V}$ as the control volume, $\tilde{S}$ as the control surface
  and $V$ is the material volume at some time $t$. We can give the material volume some property $B$ (could be mass, momentum, energy, etc)
  \begin{equation*}
    \begin{gathered}
      \stackrel[\text{change of $B$ in $V$}]{}{\frac{\text{D}}{\text{D}T} \int_V B ~\text{d}V} \quad = \\
      \stackrel[\text{local change of $B$ in $\tilde{V}$}]{}{\pdv{t} \int_{\tilde{V}} B ~\text{d}\tilde{V}} +
      \stackrel[\text{flux of $B$ accross the $\tilde{S}$}]{}{\oint_{\tilde{S}} B ~\overline{v} \cdot \text{d}\tilde{S}}
    \end{gathered}
  \end{equation*}
  (the flux term intuitively represents the properties brought into the volume from the exterior)

  A physical development of this equation can be given if we consider the density $\rho$ as the main property.
  \begin{equation*}
    \frac{\text{D}}{\text{D}T} \int_V \rho ~\text{d}V =
    \pdv{t} \int_{\tilde{V}} \rho ~\text{d}\tilde{V} +
    \oint_{\tilde{S}} \rho ~\overline{v} \cdot \text{d}\tilde{S}
  \end{equation*}
  assuming the law of conservation of mass is valid for the fluid, meaning no nuclear reactions are happening and relativistic effects are negligible
  \begin{equation*}
    \begin{gathered}
      \frac{\text{D}}{\text{D}T} \int_V \rho ~\text{d}V = 0 \\
      \implies
      \stackrel[\text{variation of mass}]{}{\pdv{t} \int_{\tilde{V}} \rho ~\text{d}\tilde{V}} +
      \stackrel[\text{traversing mass}]{}{\oint_{\tilde{S}} \rho ~\overline{v} \cdot \text{d}\tilde{S}} ~= 0
    \end{gathered}
  \end{equation*}
  we can write all of the integrals in terms of the control volume by applying Gauss's divergence theorem
  \begin{equation*}
    \begin{gathered}
      \oint_{\tilde{S}} \rho(\overline{v} \cdot \text{d}\tilde{S}) = \int_{\tilde{V}} \nabla(\rho \overline{v}) ~\text{d}\tilde{V} \\
      \implies
      \pdv{t} \int_{\tilde{V}} \rho ~\text{d}\tilde{V} +
      \int_{\tilde{V}} \nabla(\rho \overline{v}) ~\text{d}\tilde{V} \\
      = \int_{\tilde{V}} \pdv{\rho}{t} + \nabla(\rho \overline{v}) ~\text{d}\tilde{V} = 0
    \end{gathered}
  \end{equation*}
  and since the control volume is arbitrary the last expression must hold for every volume, and thus the argument of the
  integral must be null, so we get the continuity equation
  \begin{equation*}
    \pdv{\rho}{t} + \nabla(\rho \overline{v}) = 0
  \end{equation*}
  and from this equation if we make the \textit{incompressible flow} assumption we get an even more special case,
  \begin{equation*}
    \begin{gathered}
      \pdv{\rho}{t} = 0 \implies \nabla(\rho \overline{v}) = 0 \implies \nabla~\overline{v} = 0 \\
      \implies
      \pdv{v_x}{x} + \pdv{v_y}{y} + \pdv{v_z}{z} = 0
    \end{gathered}
  \end{equation*} \\
  In fluid mechanics there is a balance between complex math and visualization, drawing something that is approximately true is a great skill.
  ``Boundary layer theory by Gersten'' is a good book to read for fluid dynamics. While solving difficult fluid problems try to sketch them,
  and if that does not work it is a good indicator that some of my assumptions are off.
\end{multicols}

\mychapter{Schr\"odinger equation derivation}
\footnote{Sources:
  \href{https://youtu.be/KmFG_QNSZzA?si=pl9x9JqUh-3kMOiQ}
  {"Ch 13: Where does the Schr√∂dinger equation come from? | Maths of Quantum Mechanics" by Quantum Sense}
}

\begin{multicols}{3}
  A time evolution operator evolves the quantum state, we can collect some of its properties from intution.
  Firstly the trivial evolution in time should make the operator act as and identity.
  \begin{equation*}
    \hat{U}(0) \ket\psi = \ket\psi \implies \hat{U}(0) = \mathds{1}
  \end{equation*}
  Time evolution must also be invertible, so the inverse of the operator $U^{-1}(t)$ must exist.
  Moreover the total probability must be conserved
  \begin{equation*}
    \braket{\hat{U}(t)\psi} = \braket\psi = 1
  \end{equation*}
  So far these properties are satisfied by the class of \textit{unitary operators}, they are necessary,
  now we prove that they are also sufficient. \\

  \mytheorem{$\boldsymbol{\hat{U}(t)}$ is unitary} From the probability conservation hypothesis
  \begin{equation*}
    \begin{gathered}
      \braket{\hat{U}\psi} = \braket\psi \implies \bra\psi \hat{U}^\dagger \hat{U}\ket\psi = \bra\psi\mathds{1}\ket\psi \\
      \implies
      \bra\psi \hat{U}^\dagger \hat{U} - \mathds{1}\ket\psi = 0
    \end{gathered}
  \end{equation*}
  the composed operator acted on the inner product is hermitian
  \begin{equation*}
    \begin{gathered}
      \hat{A} \equiv \hat{U}^\dagger \hat{U} - \mathds{1} \qquad \mathcal{B}_{\perp, 1} = \{\ket{a_i}\} \\
      \hat{A}^\dagger
      = (\hat{U}^\dagger \hat{U})^\dagger - \mathds{1}^\dagger
      = \hat{U}^\dagger \hat{U} - \mathds{1} = \hat{A}
    \end{gathered}
  \end{equation*}
  we calculate the eigenvalues given its eigenbasis
  \begin{equation*}
    \begin{gathered}
      \bra\psi \hat{U}^\dagger \hat{U} - \mathds{1}\ket\psi = \bra\psi \hat{A} \ket\psi = \bra{a_i} \hat{A} \ket{a_i} \\
      = \bra{a_i} \lambda_i \ket{a_i} = 0 \implies \lambda_i =  0
    \end{gathered}
  \end{equation*}
  we determine the operator $\hat{A}$ by acting it on an arbitrary state
  \begin{equation*}
    \begin{gathered}
      \hat{A}\ket\psi = \sum_i c_i\hat{A}\ket{a_i} = \sum_i c_i\lambda_i\ket{a_i} = 0
    \end{gathered}
  \end{equation*}
  by the definition of the $\hat{A}$ operator and the invertibility condition
  \begin{equation*}
    \hat{U}^\dagger \hat{U} - \mathds{1} = 0 \implies \hat{U}^\dagger \hat{U} = \mathds{1} \implies \hat{U}^\dagger = \hat{U}^{-1}
  \end{equation*}
  thus $\hat{U}(t)$ is unitary. \\

  \mytheorem{Action of the operator}
  To find the action over the operator we expand the terms over an infinitesimal time step.
  \begin{equation*}
    \begin{gathered}
      \hat{U}(\text{d}t) = \hat{U}(0) + \dot{\hat{U}}(0)\text{d}t + \hat{O}(\text{d}t^2) \\
      \ket{\psi(\text{d}t)} = \ket\psi + \dot{\hat{U}}(0)\text{d}t\ket\psi + \hat{O}(\text{d}t^2)\ket\psi
    \end{gathered}
  \end{equation*}
  terms can be re-aranged to reveal a ``quantum derivative'' by incremental ratio limit definition
  \begin{equation*}
    \begin{gathered}
      \ket{\psi(\text{d}t)} = \ket\psi + \dot{\hat{U}}(0)\text{d}t\ket\psi + \hat{O}(\text{d}t^2)\ket\psi \\
      \implies \frac{\ket{\psi(\text{d}t)} - \ket\psi}{\text{d}t} = \dot{\hat{U}}(0)\ket\psi + \cancel{\frac{\hat{O}(\text{d}t^2)}{\text{d}t}}\ket\psi \\
      \implies \dv{t}\ket\psi = \dot{\hat{U}}(0)\ket\psi
    \end{gathered}
  \end{equation*} \\

  \mytheorem{$\boldsymbol{\dot{\hat{U}}(0)}$ is unitary}
  The unitary structure of the operator can be explicited while taking an expansion
  \begin{equation*}
    \begin{gathered}
      \mathds{1} = \hat{U}^\dagger(\text{d}t) \hat{U}(\text{d}t) \\
      \mathds{1} = \left(\hat{U}^\dagger(0) + \dot{\hat{U}}^\dagger(0)\text{d}t + \hat{O}(\text{d}t^2)\right) \cdot\left(...\right) \\
      \mathds{1} = \mathds{1} + \dot{\hat{U}}^\dagger(0)\text{d}t + \dot{\hat{U}}(0)\text{d}t + \hat{O}(\text{d}t^2) \\
      \implies \dot{\hat{U}}^\dagger(0) = -\dot{\hat{U}}(0) \\
    \end{gathered}
  \end{equation*}
  the operator is anti-hermitian when taking its first time derivative, the following can be said
  \begin{equation*}
    (i \dot{\hat{U}}(0))^\dagger = \dot{\hat{U}}^\dagger(0) i^\dagger = (i \dot{\hat{U}}(0))^\dagger
  \end{equation*}
  so by scaling the time derivative of the operator by an immaginary unit it re-gains its hermitian property,
  we will label the operator with $\hat{H}$ to reach the semi-final form of the time evolution equations
  \begin{equation*}
    i\dv{t}\ket\psi = \hat{H}\ket{\psi(0)} \quad \sim \quad \dv{\mathcal{L}}{t} = -\dv{t}E
  \end{equation*}
  from now on physical intuition relates this quantum expression with the energy generator from classical physics, thus we make
  the $\hat{H}$ operator the \textit{hamiltonian}, and by adjusting the units with a constant of proportionality we reach the final form of the equations
  \begin{equation*}
    i\hbar\dv{t}\ket\psi = \hat{H}\ket{\psi(0)}
  \end{equation*}
  We \underline{needed} that complex number so that the time evolution can be unitary so that it conserves probability and
  the hamiltonian shows up because from classical physics generates time evolution.
\end{multicols}




\mychapter{The origin of the commutator}
\footnote{Sources:
  \href{https://youtu.be/2_KVbtyufq8?si=KxYFdZ__YfD6ZzKm}
  {"The origin of the commutator" by Michael Penn}
}

\begin{multicols}{3}
  A Lie group is a group which is also a smooth manifold. A manifold is a generalization of a surface.
  The associated Lie algebra, $g$, is the tangent space at 1 in $G$.
  What are some natural operations for g?
  It is closed under addition
\end{multicols}



It is closed under addition
a, b in g
so
exists curves A(t), B(t) s.t.
A(0) = B(0) = 1
a = A'(0), b = B'(0)
note:
$dv t (A(t)B(t))|_{t=0} = derivatives of product = a + b$
and A(t)B(t) is a curve passing the origin so
a + b in g

It is closed under scalar multiplication (homework)

Is it closed under some multiplication. How would we even define it?
what about?
ab = A'(0)B'(0) = dv t dv s(A(t)B(s))|t=0, s=0
maybe A'(0)B'(0) this is outside tangent space, maybe bad idea

Ok so g is a vector space

A(t), B(t) inside G, A(0) = B(0) = 1, a = A'(0), b = B'(0) in g

Fix s and define
$c_s(t) = A(s)B(t)A(s)^-1, c_s(0) = 1$

$dv t c_s(t)|t=0 = A(s)B'(0)A^-1(s) = A(s)bA^-1(s) in g$
$implies forall s A(s)bA^-1(s) in g$
$implies g contains dv s (A(s)bA^-1(s))|s=0$

use:
$dv s A^-1 = -A^-1(s)A'(s)A^-1(s)$

$= A'(0)bA^-1(0) - A(0)bA^-1(0)A'(0)A^-1(0), A^-1(0) = 1, A'(0) = a$
= ab - ba

Definition of [a, b] = ab - ba tells us that this lie braket is a nice
operation on g


"Naive Lie Theory by Stillwell" has a nice introduction to Lie groups
and Lie algebras.





\mychapter{Tensor product}
\footnote{Sources: \href{https://youtu.be/K7f2pCQ3p3U?si=9kCDjIPKh2ep6fXa}{``What is a tensor anyway?? (from a mathematician)'' by Micheal Penn}}


\paragraph{\textbf{Keywords}}
Formal product, quotient space, coset, tensor product, basis

\begin{multicols}{3}
\end{multicols}


\end{document}
